# Continual Active Self-Learning (CASL): An Active Learning Approach for Reducing Data Budget In Self-Supervised Pretraining
This is the repository for the research on reducing the data budget required on pretraining a second layer pretrained model. Here I used active learning to reduce the data budget required in pretraining a self-supervised model
